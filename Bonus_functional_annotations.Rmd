


# <a name="functanno"></a> Bonus exercise: from differential expression to biological knowledge

## Introduction to functional annotation
In this part of the exercise we will address the question which biological processes are affected in the experiment; in other words we will functionally annotate the results of the analysis of differential gene expression (performed in the main part of the exercise). We will use [Gene Ontology (GO) term](http://geneontology.org/) and [reactome pathway](http://reactome.org/) annotations.

When performing this type of analysis one has to keep in mind that the analysis is only as accurate as the annotation available for your organism, so if working with non-mainstream model organisms which do have most of the annotations only electronically inferred (as opposed to direct evidence), the results may not be fully reflecting the actual situation.

There are many methods to approach the question which biological processes and pathways are overrepresented amongst the differentially expressed genes, compared to all genes included in the analysis. They use several types of statistical tests (e.g. hypergeometric test, Fisher's exact test), and many have been developed with microarray data in mind. Not all of these methods are appropriate for RNA-seq data, which as you remember from the lecture, exhibit length bias in power of detection of differentially expressed genes (i.e. longer genes, which tend to gather more reads, are more likely to be detected as "differentially expressed" than shorter genes, solely because of the length).

We will use the R / Bioconductor package [goseq](http://bioconductor.org/packages/release/bioc/html/goseq.html), specifically designed to work with RNA-seq data. This package provides methods for performing Gene Ontology  and pathway analysis of RNA-seq data, taking length bias into account.

In this part, we will use the same data as in the main workflow. The starting point of the exercise is the file with results of the differential expression produced in the main part of the exercise.

Running functional annotation is typically not computationaly-heavy and it may be easier to run it on your local computer. Therefore this module can be performed on Uppmax or on your local computer. For the latter you need have [R statistical programming language](https://cran.r-project.org/) installed. An optional graphical interface to R such as [RStudio](https://www.rstudio.com/) is also recommended.

Follow :computer: icon for running the module on Uppmax. Follow :floppy_disk: to run things on your own computer. 

## Setting-up workspace 

:computer: **Start an R session** This is done by simply typing R on the uppmax command line, although I would sincerly recommend to run [RStudio](https://www.rstudio.com/) on your own computer, <b>note that this would require you to download and install it, but considering this is a bonus exercise that could still be worth it in the long run</b>
<details>
{% highlight bash %}
R
{% endhighlight %}
</details>
<br />

:floppy_disk: **Install packages** used in the exercise. You can do it by pasting the following two commands in R session:
<br />
 `source("http://bioconductor.org/biocLite.R")`
 <br />
 `biocLite(c("goseq","GO.db","reactome.db","org.Mm.eg.db"))`
<br />

<br />
:computer: :floppy_disk: To perform the exercise you will need data included in the following location at Uppmax:
<br />
 `/sw/courses/ngsintro/rnaseq/bonus/funannot`
<br />
<br />

:floppy_disk: **Copy over** the directory to your working directory on your local computer
<details>
 <summary>:key: Click to see an example of a command</summary>
 {% highlight bash %}
 scp -r <your_username>@milou.uppmax.uu.se:/sw/courses/ngsintro/rnaseq/bonus/funannot ./
 {% endhighlight %}
</details>
<br />

:computer: **Copy over** the directory to your working space _transcriptome_
<details>
<summary>:key: Click to see an example of a command</summary>
{% highlight bash %}
cp -r /sw/courses/ngsintro/rnaseq/bonus/funannot/ /$resDir/transcriptome/
{% endhighlight %}
</details>
<br />

## Workflow

:computer: **Load R and R modules** required in the exercise:
 <details>
 <summary>:key: Click to see an example of a command</summary>
 {% highlight bash %}
 module purge
 module load R/3.3.0
 module load R_packages/3.3.0
 {% endhighlight %}
 </details>
<br />

:computer: **Enter** the exercise working directory:
<details>
<summary>:key: Click to see how</summary>
{% highlight bash %}
cd $resDir/transcriptome/funannot
{% endhighlight %}
</details>
<br />

:computer: **Install the packages** <b>This you only need to do once per computer! Go into your R session:</b>
<details>
<summary>:key: Click to see how</summary>
{% highlight R %}
source("https://bioconductor.org/biocLite.R")
biocLite("goseq")
biocLite("GO.db")
biocLite("reactome.db")
biocLite("org.Mm.eg.db")
{% endhighlight %}
</details>
<br />

:computer: **To perform the functional annotation**
<details>
<summary>:key: Click to see how</summary>
{% highlight R %}
################################################################
## prepare paths and directories where results will be saved ###
################################################################
require("goseq")
require("GO.db")
require("reactome.db")
require("org.Mm.eg.db")

dir=getwd()
results.dir="GO_react_results"
results.path=file.path(dir, results.dir)
dir.create(results.path)

## read in the data table (results of differential expression analysis using edgeR, from the main workflow)
de_res=read.table("./data/DE_allReads.txt",sep="\t", header=TRUE, stringsAsFactors=FALSE, quote="")

## add gene length information to df with results
len=read.table("./annot/mm10_gene_len.txt", sep="\t", quote="", header=TRUE)
de_res_len=merge(de_res,len, by="ensembl_gene_id")

################################################################################
## get functional annotations from R db packages org.Mm.eg.db and reactome.db ##
################################################################################
go=as.data.frame(org.Mm.egGO2ALLEGS)
colnames(go)=c("gene_id","category","Evidence","Ontology")

react=as.data.frame(reactomeEXTID2PATHID)
colnames(react)=c("category","gene_id")
reactomeids=as.data.frame(reactomePATHID2NAME)
colnames(reactomeids)=c("category","path_name")
#the rows with category id - category name are duplicated, remove the duplicates
reactomeids=subset(reactomeids, !duplicated(reactomeids$category))

#############################
### What will be analysed ###
#############################

## select only genes with entrez gene id
## GO term and reactome pathway annotations are mapped to entrez gene ids
de_res_len_go=de_res_len[complete.cases(de_res_len[,6]),]

## remove lines with non-unique entrez gene id
de_res_len_go_uniq=subset(de_res_len_go, !duplicated(de_res_len_go[,6]))

## list of all genes included in the analysis
allgenes=de_res_len_go_uniq$entrezgene

## named vector with gene lengths (element names are entrez gene ids)
genelen=de_res_len_go_uniq$transcript_length
names(genelen)=de_res_len_go_uniq$entrezgene

## named vectors of differential expression status, i.e. "1" means "gene is DE", "0" means "it is not"
## element names are entrez gene ids
## this vector must be the same length as genelen vector and all element names must be unique

#select the downregulated genes at FDR<0.05
dn.genes=de_res_len_go_uniq$entrezgene[(de_res_len_go_uniq$FDR<0.05 & de_res_len_go_uniq$logFC<0 )]
#construct the named vector
gene.vector.de.dn=as.integer(allgenes%in%dn.genes)
names(gene.vector.de.dn)=allgenes

up.genes=de_res_len_go_uniq$entrezgene[(de_res_len_go_uniq$FDR<0.05 & de_res_len_go_uniq$logFC>0 )]
gene.vector.de.up=as.integer(allgenes%in%up.genes)
names(gene.vector.de.up)=allgenes

##################################################################################
## calculate the gene length bias (using nullp, a function from goseq package) ###
##################################################################################
pwf.de.up=nullp(gene.vector.de.up, bias.data=genelen)
pwf.de.dn=nullp(gene.vector.de.dn, bias.data=genelen)


######################################################################################
## get over-represented GO terms in genes up- and down-regulated in the experiment ###
## obtain FDR by adjusting p values using Bonferroni-Hochberg method               ###
######################################################################################
go.up=goseq(pwf.de.up, gene2cat=go)
go.up.adj=go.up[p.adjust(go.up$over_represented_pvalue, method="BH")<0.1,]

go.dn=goseq(pwf.de.dn, gene2cat=go)
go.dn.adj=go.dn[p.adjust(go.dn$over_represented_pvalue, method="BH")<0.1,]


###############################################################################################
## get over-represented reactome pathways in genes up- and down-regulated in the experiment ###
## obtain FDR by adjusting p values using Bonferroni-Hochberg method                        ###
###############################################################################################
react.up=goseq(pwf.de.up, gene2cat=react)
react.up.adj=react.up[p.adjust(react.up$over_represented_pvalue, method="BH")<0.1,]
react.up.adj.annot=merge(react.up.adj, reactomeids, by="category", sort=F)

react.dn=goseq(pwf.de.dn, gene2cat=react)
react.dn.adj=react.dn[p.adjust(react.dn$over_represented_pvalue, method="BH")<0.1,]
react.dn.adj.annot=merge(react.dn.adj, reactomeids, by="category", sort=F)


#############################
## save results as tables ###
#############################
go.up.file="GO_term_genes_up.txt"
go.up.path=file.path(results.path, go.up.file)
write.table(go.up.adj, go.up.path, col.names=TRUE, row.names=FALSE, sep="\t", quote=FALSE)

go.dn.file="GO_term_genes_dn.txt"
go.dn.path=file.path(results.path, go.dn.file)
write.table(go.dn.adj, go.dn.path, col.names=TRUE, row.names=FALSE, sep="\t", quote=FALSE)

react.up.file="reactome_pway_genes_up.txt"
react.up.path=file.path(results.path, react.up.file)
write.table(react.up.adj.annot, react.up.path, col.names=TRUE, row.names=FALSE, sep="\t", quote=FALSE)

react.dn.file="reactome_pway_genes_dn.txt"
react.dn.path=file.path(results.path, react.dn.file)
write.table(react.dn.adj.annot, react.dn.path, col.names=TRUE, row.names=FALSE, sep="\t", quote=FALSE)
{% endhighlight %}
</details>
<br />
The results will be saved in the directory *GO\_react\_results*.
<br />
<br />
<br />


## Interpretation
:computer: :floppy_disk: The results are saved as tables in the directory *GO\_react\_results*.
<br />

The columns of the results tables are:  
|  category  | over_represented_pvalue | under_represented_pvalue | numDEInCat | numInCat  | term | ontology |
<br />

You can view the tables in a text editor, and try to find GO terms and pathways relevant to the experiment using a word search functionality.  
<br />

:floppy_disk: The results are also collected in the following objects:  
{% highlight bash %}
go.dn.adj
go.up.adj
react.dn.adj.annot
react.up.adj.annot
{% endhighlight %}

<br />
You can explore the results either by printing them all on the screen  

<details>
<summary>:key: Click to see example </summary>
{% highlight bash %}
go.dn.adj
{% endhighlight %}
</details>
<br />
or by performing a string search using grep
<details>
<summary>:key: Click to see example </summary>
{% highlight bash %}
grep("myelin", go.dn.adj$term,  value=T)
{% endhighlight %}
</details>
<details>
<summary>:key: Click to see example </summary>
{% highlight bash %}
grep("neuro", go.dn.adj$term,  value=T)
{% endhighlight %}
</details>
<br />

:open_mouth: Do you think the functional annotation reflects the biology of the experiments we have just analysed?  
<br />
<br />
[Jump to the top](#begin)

# <a name="exon"></a> Bonus exercise: exon usage

## Introduction to differential exon usage

Multi-exon genes are affected by alternative
splicing and thus can express a variety of different
transcripts from the same genomic sequence. Differences in the relative expression of these isoforms between tissues and species occur naturally between cell types and allow cells to adapt to the environment.

It is important to distinguish differential transcript usage (DTU) from gene-level differential expression (which was covered in the main part of the exercise) and from transcript-level differential expression. DTU considers changes in the **proportions** of the isoforms of a gene that are expressed as opposed to changes of the individual transcript levels.

Although the main units of interest are the transcripts, it has been difficult to obtain accurate and precise transcript-level expression estimates due to the extensive overlap between different transcripts. To circumvent that number of methods have been developed that, instead of estimating expression levels of transcripts, analyse levels of transcript building blocks (exons).  Hence, differential exon usage (DEU) can be viewed as a proxy to the differential transcript usage.

Note that DEU is a more general concept than alternative splicing since it also includes changes in the usage of alternative transcript start sites and polyadenylation sites, which can cause differential usage of exons at the 5' and 3' boundary of transcripts.

The Bioconductor package **DEXSeq** implements a method to test for differential exon usage in comparative
RNA-Seq experiments. By differential exon usage we mean changes in the **relative** usage
of exons caused by the experimental condition. The relative usage of an exon is defined as number of transcripts from the gene that contain this exon vs. number of all transcripts from the gene.

In this exercise we will use reads mapped to chromosome 11 only as performing this analysis on entire data set is quite time consuming and requires considerable computing power. The starting point are files with reads summarised per each annotated exon, prepared beforehand by us.

This module can be performed on Uppmax, or on your local computer if you have installed [R statistical programming language](https://cran.r-project.org/) and (optionally) a graphical interface to R such as [RStudio](https://www.rstudio.com/).

Follow :computer: icon for running the module on Uppmax. Follow :floppy_disk: to run things on your own computer. 

## Setting-up workspace 

Libraries to install and load if exercise is performed locally

:floppy_disk: **Install packages** used in the exercise. You can do it by pasting the following two commands in R session:

 `source("http://bioconductor.org/biocLite.R")`
 
 `biocLite("DEXSeq")`

<br />
:floppy_disk: In addition you may need to install X11 app ([XQuartz](https://www.xquartz.org/) on MacOS) to produce the html report.

<br />
:computer: :floppy_disk: To perform the exercise you will need data included in the following location at Uppmax:

  `/sw/courses/ngsintro/rnaseq/bonus/exon`

<br />
:computer: **Copy over** the directory _transcriptome_ folder
<details>
<summary>:key: Click to see an example of a command</summary>
{% highlight bash %}
cp -r /sw/courses/ngsintro/rnaseq/bonus/exon $resDir/<username>/transcriptome
{% endhighlight %}
</details>
<br />

:floppy_disk: **Copy over** the directory to your workspace on your local computer
<details>
<summary>:key: Click to see an example of a command</summary>
{% highlight bash %}
scp -r YOUR_LOGIN@milou.uppmax.uu.se:/sw/courses/ngsintro/rnaseq/bonus/exon ./
{% endhighlight %}
</details>
<br />

## Workflow

:computer: **Load R and R modules** required in the exercise:
<details>
<summary>:key: Click to see how</summary>
 {% highlight bash %}
 module purge
 module load R/3.3.0
 module load R_packages/3.3.0
 {% endhighlight %}
</details>
<br />

**Enter** the exercise working directory:
<details>
<summary>:key: Click to see how</summary>
{% highlight bash %}
cd $resDir/transcriptome/exon
{% endhighlight %}
</details>
<br />

:computer: **Perform the functional annotation**, save as deu.R
<details>
<summary>:key: Click to see how</summary>
{% highlight R %}
#############################
## prepare paths and files ###
#############################
require("DEXSeq")

inDir="./data"
countFiles = list.files(inDir, pattern=".txt$", full.names=TRUE)

gff="Mus_musculus.GRCm38.85.chr11.flat.dexseq.gff"

## read in the information on the experiment
## OBS! the order of the samples in the exp object must be the same as the order of files in the countFiles object
exp=read.table("experiment.txt", sep="\t", header=T)

## read in the data and create the DEXSeq object
## the model to test is specified at this step
dxd = DEXSeqDataSetFromHTSeq(
  countFiles,
  sampleData=exp,
  design= ~ sample + exon + condition:exon,
  flattenedfile=gff )

## normalise to sequencing depth
dxd = estimateSizeFactors( dxd )
## dispersion estimation to distinguish technical and biological variation (noise) from real effects on exon usage due to the different conditions
dxd = estimateDispersions( dxd )
plotDispEsts( dxd )

#########################################
## testing for differential exon usage ##
#########################################

dxd = testForDEU( dxd )
dxd = estimateExonFoldChanges( dxd, fitExpToVar="condition")

## read in the data and create the DEXSeq object
dxr = DEXSeqResults( dxd )

###################################
## save results as html & table ###
###################################

DEXSeqHTML( dxr, FDR=0.1, color=c("#FF000080", "#0000FF80") )

res=dxr[complete.cases(dxr[,7]),]
res=res[res$padj<0.1,]
write.table(res,"deu_signif_exons.txt", col.names=TRUE, row.names=FALSE, sep="\t", quote=FALSE)
{% endhighlight %}
</details>
<br />

<br />
:computer: :floppy_disk: The results in html format are saved in the directory ***DEXSeqReport***. For detailed description of the individual report sections please consult [DEXSeq user manual](http://bioconductor.org/packages/release/bioc/vignettes/DEXSeq/inst/doc/DEXSeq.pdf). Additionally, a table with significant exons and statistics relevant to their differential usage ***deu\_signif\_exons.txt*** is saved in the working directory.
<br />

:open_mouth: How many differentially used exons were identified in the data? Do you think this result makes sense?
<br />
<br />
[Jump to the top](#begin)
<br />
<br />


#  <a name="visual"></a> Bonus exercise: RNA-seq visualisation

## Introduction

Data visualisation is important to be able to clearly convey results,
but can also be very helpful as tool for identifying issues and
noteworthy patterns in the data. In this part you will use the bam
files you created earlier in the RNA-seq lab and use IGV (Integrated
Genomic Viewer) to visualize the mapped reads and genome
annotations. In addition we will produce high quality plots of both
the mapped read data and the results from differential gene
expression.

## IGV

If you are already familiar with IGV you can load the mouse genome and
at least one bam file from each of the treatments that you created
earlier. The functionality of IGV is the same as if you look at
genomic data, but there are a few of the features that are more
interesting to use for RNA-seq data.

[Integrated genomics viewer](http://software.broadinstitute.org/software/igv/) from Broad Institute is a nice graphical
interface to view bam files and genome annotations. It also has tools
to export data and some functionality to look at splicing patterns in
RNA-seq data sets. Even though it allows for some basic types of
analysis it should be used more as a nice way to look at your mapped
data. Looking at data in this way might seem like a daunting approach
as you can not check more than a few regions, but in in many cases it
can reveal mapping patterns that are hard to catch with just summary
statistics.

For this tutorial you can chose to run IGV directly on your own computer (follow :floppy_disk:)
or on Uppmax (follow :computer:). If you chose to run it on your own computer you will
have to download some of the bam files (and the corresponding index
files) from Upppmax. If you have not yet installed IGV you also
have to get a copy of the program. 

:floppy_disk: **Copy bam files** to your local computer and **run IGV**
<details>
<summary>:key: Click to see how to transfer files from Uppmax</summary>
{% highlight bash %}
scp username@milou.uppmax.uu.se:<the path to your results directory goes here>/transcriptome/bamfile.bam .
{% endhighlight %}
NB! Use the sorted bam files and also copy over the .bai files
</details>
<br />

:computer:  **Log in to Uppmax** in a way so that the generated graphics are exported via the network to your screen
<br />
:computer:  Method 1. Login in to Uppmax with X-forwarding enabled
<details>
<summary>:key: Click to see how</summary>
{% highlight bash %}
ssh -Y username@milou.uppmax.uu.se
ssh -Y computenode
{% endhighlight %}
</details>
This will allow any graphical interface that you start
on your compute node to be exported to your computer. However, as
the graphics is exported over the network it can be fairly slow in
redrawing windows and the experience can be fairly poor.

:computer: Method 2. Go to [Milou-gui](https://milou-gui.uppmax.uu.se/main/)

Once you log into this interface you will have a linux desktop
interface in a browser window. This interface is running on the login
node so if you want to do any heavy lifting you need to login to your
reserved compute node also here. This is done by opening a terminal in
the running linux environment and log on to your compute node as before
NB! If you have no active reservation you have to do that first.

<br />
:computer: **Load necessary modules** and start IGV
{% highlight bash %}
module load bioinfo-tools
module load IGV/2.3.40
igv-core
{% endhighlight %}




<br />
:computer: :floppy_disk: Once we have the program running you select the genome that you would
like to load. As seen in the image below. 

![](Images/IGV-genome.png)

Note that if you are working with a genome that are not part of the
available genomes in IGV, one can create genome files from within
IGV. Please check the manual of IGV for more information on that.

To open your bam files click on File and chose the option "Load from
file" select your bam file and make sure that you have a .bai index
for that bam file in the same folder. You can repeat this and open
multiple bam files in the same window, which makes it easy to compare
samples. For every file you open a number of panels are opened that
visualize the data in different ways. The first panel named "Coverage"
summarize the coverage of basepairs in the window you have zoomed
to. The second that ends with the name "Junctions" show how reads were
spliced to map, eg. reads that stretch over multiple exons are split
and mapped one part in one exon and the next in another exon. The
third panel shows the reads as they are mapped to the genome. If one
right click with the mouse on the read panel there many options to
group and color reads. 

To see actual reads you have to zoom in until the reads are
drawn on screen. If you have a gene of interest you can also use
the search box to directly go to that gene. 

If you for example search for the gene "Mocs2" you should see a decent
amount of reads mapping to this region. For more detailed information
on the splice reads you can instead of just looking at the splice
panel right click on the read panel and select "Sashimi plots" This
will open a new window showing in an easy readable fashion how reads
are spliced in mapping and you will also be able to see that there are
differences in between what locations reads are spliced. This hence
gives some indication on the isoform usage of the gene.

To try some of the features available in IGV you can try to address the following
questions. 

:open_mouth: Are the reads you mapped from a stranded or unstranded library?

:open_mouth: Pick a gene from the toplist of most significant genes from the DE
analysis and search for it using the search box in IGV. Would you say that
the pattern you see here confirms the gene as differentially expressed
between treatments?

:open_mouth: One can visualize all genes in a given pathway using the gene list
option under "Regions" in the menu. Would you agree with what they
state in the paper about certain pathways being down-regulated. If you need
hints for how to proceed see [Gene List tutorial at Broad](http://software.broadinstitute.org/software/igv/gene_list_view).
<br />
<br />


# Create publication ready plots from RNA-seq data

Creating high quality plots of RNA-seq analysis are most easily done
using [R](https://www.r-project.org). Depending on your profiency in
reading r-code and using R you can in this section either just call
scripts from the command lines with a set of arguments or you can open
the r-script in a text editor and run the code step by step from an
interactive r-session. Irrespective of the method you choose make sure
you load the same R modules as before and do all steps on a compute
node.

:computer: **Load R module and R packages**
<details>
<summary>:key: Click to see how </summary>
{% highlight bash %}
module load R/3.3.0
module load R_packages/3.3.0
{% endhighlight %}
</details>
<br />

Some of the example plots we generate here are based on the results from the DE analysis so
perform all of these steps from within the DE folder that you created earlier. 

Start by copying the scripts from the course folder to your DE directory.

:computer: **Move** to DE and **copy** R-scripts
<details>
<summary>:key: Click to see how to copy the files to your DE folder</summary>
{% highlight bash %}
cd $resDir/transcriptome/DE
cp /sw/courses/ngsintro/rnaseq/bonus/visual/*.R .
{% endhighlight %}
</details>

You should now have four files in your DE folder.  <br /> <br /> We
start off by creating similar plots to how data is visualised in IGV,
but using R means that we could add other types of information that
are not implemented in IGV.

:mag: To look at read coverage in our bam files for a gene of interest
(pick one that was reported to be differentially expressed) and go to
the Ensembl to identify genomic coordinates and chromosome location
for this gene.

:computer: Make a script named genePlot.R
<details>
<summary>:key: Click for the code to copy into the new file</summary>
{% highlight R %}
.libPaths(c("/sw/courses/ngsintro/rnaseq_2016/R-packages/3.3.0", "/pica/sw/apps/R_packages/3.3.0/milou", "/pica/sw/apps/R/x86_64/3.3.0/milou/lib64/R/library"))

# For running as command line script and parsing options from command line
args = commandArgs(trailingOnly=TRUE)
# test if correct number of arguments are given as input: if not, return an error
if (length(args)<3) {
    stop("Please supply chromosome number as well as start and stop position for the plot\n Example: Rscript genePlot.R 2 234243 238555",
         call.=FALSE)
}

library(Gviz)
library(EnsDb.Mmusculus.v79)
edb <- EnsDb.Mmusculus.v79
gen <- "mm10"
chr <- args[1] # parse the first argument after the r-script to chr
start <- args[2] # parse the second argument after the r-script to start
stop <- args[3] # parse the second argument after the r-script to stop
# Collect the sorted bamfile names from bams folder
bamFiles <- list.files("~/glob/transcriptome/bams/", pattern = "*sorted.bam$",
                       full.names = TRUE, recursive = TRUE)
# Allow for using different chromosome names than ucsc
options(ucscChromosomeNames=FALSE)

# create track see Gviz manual for details
gat <- GenomeAxisTrack()
gr <- getGeneRegionTrackForGviz(edb, chromosome = args[1], start = start, end = stop)
genome(gr) <- "mm10"

alTracklist <- lapply(seq_along(bamFiles), function(x) AlignmentsTrack(
                                                           bamFiles[[x]],
                                                           chromosome = chr,
                                                           genome = gen,
                                                           name = substring(bamFiles[x], 41,50)))
# Merge all tracks
toPlot <- append(list(gat, GeneRegionTrack(gr)),alTracklist)
width = 14
height = 14

# Plot to pdf
pdf("Coverage.pdf", width = width, height = height)  
plotTracks(toPlot, type = c("coverage"))
dev.off()
pdf("Sashimi.pdf", width = width, height = height)  
plotTracks(toPlot, type = c("sashimi"))
dev.off()
{% endhighlight %}
</details>

:computer: Run the newly created script
{% highlight bash %}
Rscript genePlot.R chromosome start stop
{% endhighlight %}

<details>
<summary>:key: Click to see a an real example</summary>
{% highlight bash %}
Rscript genePlot.R 14 31217860 31230350 
{% endhighlight %}
</details>
<br />
This will generate a plot named coverage.pdf that show annotations and
read coverage for the 6 bam files we use in the analysis for
chromosome 14 from postion 31217860 to 31230350. 
<br />
:floppy_disk: To view the file copy it from Uppmax to your own computer and open it in a
pdf reader.
<details>
<summary>:key: Click to see command to copy files</summary>
{% highlight bash %}
scp username@milou.uppmax.uu.se:<the path to your results directory goes here>/transcriptome/DE/coverage.pdf .
{% endhighlight %}
Make sure you run this command from your own computer
</details>
<br />

Besides this type of plot that sort of mimics what can be done in IGV, R
makes it possible to visualise patterns of gene expression in many
different ways. Here we will create a few different plots that is
often seen and used in RNA-seq expression analysis.
<br />
<br />

## MDS plot 

A popular way to visualise general patterns of gene expression in your
data is to produce either PCA (Principal Component Analysis) or MDS
(MultiDimensional Scaling) plots. These methods aim at summarizing the
main patterns of expression in the data and display them on a
two-dimensional space and still retain as much ingformation as
possible. To properly evaluate these kind of results is non-trivial,
but in the case of RNA-seq data we often use them to get an idea of
the difference in expression between treatments and also to get an idea
of the similarity among replicates. If the plots shows clear clusters
of samples that corresponds to treatment it is an indication of
treatment actually having an effect on gene expression. If the
distance between replicates from a single treatment is very large it
suggests large variance within the treatment, something that will
influence the detection of differentially expressed genes
between treatments.

To generate a MDS plot showing that show the the two leading fold
changes in gene expression between samples run the MAplot.R script as
this.

:computer: Make a R script name MDSplot.R
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight R %}
# Load library
library(edgeR)

# Read in DE data
deResults <- list.files("~/glob/transcriptome", pattern = ".RData",
                        recursive = TRUE, full.names = TRUE)
load(file = deResults)
load("DEdata.RData")

# Generate PDF
pdf("MDS-plot.pdf")
plotMDS(data.cds, labels = sample.groups)
dev.off()
{% endhighlight %}
</details>
<br />

:computer: Run the newly created script named MDSplot.R
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight bash %}
Rscript MDSplot.R 
{% endhighlight %}
</details>
<br />
This generates another pdf file named MAplot.pdf in the DE folder. To
view it copy it to your local disk as before.
<br />

:open_mouth: Based on these results are you surprised that your DE analysis
detected a fairly large number of significant genes?
<br />

## MA-plot and Volcanoplot

One can also visualize the actual results of a differential gene
expresssion analysis in many different ways. One way is by generating
a MA-plot that plots the mean expression and estimated log ratios for
all genes in an analysis.

To create an MA plot for your analysis you can run the script called
MAplot.R from your DE folder. It will read in the results from the DE
analysis that you did earlier and produce the plot saved as MA-plot.pdf.

:Computer: Make a R script named MAplot.R
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight R %}
#Load library
library(edgeR)
# Read in DE data
# deResults <- list.files("~/glob/transcriptome", pattern = ".RData", recursive = TRUE, full.names = TRUE)
load(file = "DEdata.RData")

# Generate PDF
pdf("MA-plot.pdf")
plotSmear(lrt, de.tags = detags)
dev.off()
{% endhighlight %}
</details>
<br />

:computer: Run the newly created script MAplot.R
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight bash %}
Rscript MAplot.R
{% endhighlight %}
</details>
<br />

:open_mouth: What do you think the red dots represent?
<br />

A related type of figure will instead plot fold change (on log2 scale) on the x-axis
and -log10 p-value on the y-axis. Scaling like this means that genes
with lowest p-value will be found at the top of the plot. In this example
we will highligt (in red) the genes that are significant at the 0.05
level after correction for multiple testing and that have an estimated fold
change larger than 4 (log2 (4) = 2).

:computer: Run the script named Volcano.R
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight bash %}
Rscript Volcano.R
{% endhighlight %}
</details>
<br />

:open_mouth: Anything noteworthy about the patterns in the plot?
<br />

Other type of popular plots for genome-wide expression patterns is to
create heatmaps for sets of genes. If you run the script called
heatmap.R from the folder where your DE is saved it will extract the
50 genes that have the lowest p-value in the experiment and create a
heatmap from these. In addition to colorcoding the expression levels
over samples for the genes it also clusters the samples and genes
based on inferred distance between them.

:computer: Run the script named heatmap.R
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight bash %}
Rscript heatmap.R
{% endhighlight %}
</details>
<br />
:open_mouth: Compare this plot to a similar plot in the paper behind the data.
<br />
Most of these plots can be done with a limited set of code. In many
cases these "standard" plots can be created with two to three lines of
code as the packages that has been written to handle RNA-seq
expression data often contains easy to use functions for generating
them.

<br />
<br />
[Jump to the top](#begin)

<br />
<br />



# <a name="assembly"></a> Bonus exercise: transcriptome assembly


# Transcriptome De Novo Assembly

## Trinity

Trinity is one of several de novo transcriptome assemblers. By efficiently constructing and analyzing sets of de Bruijn graphs, Trinity reconstructs a large fraction of transcripts, including alternatively spliced isoforms and transcripts from recently duplicated genes.
This approach provides a unified solution for transcriptome reconstruction in any sample, especially in the absence of a reference genome.

Grabherr MG, Haas BW, Yassour M et al. (2011) Full-length transcriptome assembly from RNA-Seq data without a reference genome.
Nature Biotechnology.
2011 May 15;29(7):644-52.

## Getting started

Trinity combines three independent software modules: Inchworm, Chrysalis, and Butterfly, applied sequentially to process large volumes of RNA-Seq reads.
Trinity partitions the sequence data into many individual de Bruijn graphs, each representing the transcriptional complexity at at a given gene or locus, and then processes each graph independently to extract full-length splicing isoforms and to tease apart transcripts derived from paralogous genes.
Briefly, the process works like so:

Inchworm assembles the RNA-Seq data into the unique sequences of transcripts, often generating full-length transcripts for a dominant isoform, but then reports just the unique portions of alternatively spliced transcripts.

Chrysalis clusters the Inchworm contigs into clusters and constructs complete de Bruijn graphs for each cluster.
Each cluster represents the full transcriptonal complexity for a given gene (or sets of genes that share sequences in common).
Chrysalis then partitions the full read set among these disjoint graphs.

Butterfly then processes the individual graphs in parallel, tracing the paths that reads and pairs of reads take within the graph, ultimately reporting full-length transcripts for alternatively spliced isoforms, and teasing apart transcripts that corresponds to paralogous genes.

A basic recommendation is to have 1G of RAM per 1M pairs of Illumina reads in order to run the Inchworm and Chrysalis steps.
Simpler transcriptomes require less memory than complex transcriptomes.
Butterfly requires less memory and can also be spread across multiple processors.

The entire process can require ~1 hour per million pairs of reads in the current implementation.
There are various things that can be done to modify performance.
Please review the guidelines in the official Trinity documentation for more advice on this topic.
Typical Trinity usage is as follows:

{% highlight bash %}
Trinity --seqType (fq for fastq or fa for fast) --left ~/path/to/reads_1.fq --right ~/path/to/reads_2.fq (or --single for single reads) --CPU 4 --output ~/path/to/output_dir
{% endhighlight %}


## Exercise 1: Running Trinity

In the following exercise you will have chance to run trinity on a data set that is suitable to be finished within a short lab session. Note that for many larger data sets and/or complex transcriptomes running times and memory requirements might be much larger than in this example. The actual commands to run trinity is very easy and the manual at <https://github.com/trinityrnaseq/trinityrnaseq/wiki> answers most questions related to running the program. The major challenge with running _de-novo_ assembly projects is not to get the programs to run. but rather to evaluate the results after the run. In many cases a very large number of potential transcripts are generated and often try to use sequence properties to filter the initial data. In addition one often tries to compare the obtained sequences to closely related species, try to predict open reading frames to get a feeling for how the experiment has turned out. In order to get a feeling for this we will in the exercise assemble two data sets and use simple unix tool to calculate basics stats on the assembled sequences. For this to be a meaningful exercise you should not look at the hints prior to trying some commands your self. The key to get going with these types of analysis is to realize that one does not need a specialised program to collect basic summary statistics from text files (note that fasta files are simple text files of a specified structure).

Have a look at the example data used in this exercise.
The data is obtained from mouse dendritic cells (mouse\_left.fasta and mouse\_right.fasta and) and a whitefly (whitefly_both.fasta), and the files are located in `/sw/courses/ngsintro/rnaseq/bonus/denovo/`.
The mouse data is strand-specific (RF), the whitefly data is unstranded.
For strand-specific data, specify the library type.
There are four library types:

Paired reads:
RF: first read (/1) of fragment pair is sequenced as anti-sense (reverse(R)), and second read (/2) is in the sense strand (forward(F)); typical of the dUTP/UDG sequencing method.
FR: first read (/1) of fragment pair is sequenced as sense (forward), and second read (/2) is in the antisense strand (reverse)

Unpaired (single) reads:
F: the single read is in the sense (forward) orientation
R: the single read is in the antisense (reverse) orientation

By setting the --SS\_lib\_type parameter to one of the above, you are indicating that the reads are strand-specific.
By default, reads are treated as not strand-specific.


:computer: Load modules and copy data
<details>
<summary>:key: Click to see how to do this</summary>
{% highlight bash %}
module load bioinfo-tools 
module spider trinity
module load trinity/x.x.x
mkdir $resDir/transcriptome/trinity
cp /sw/courses/ngsintro/rnaseq/bonus/assembly/*.fasta $resDir/transcriptome/trinity/
{% endhighlight %}
</details>
<br />

:mag: Check the manual of Trinity again and try to figure out what parameters and settings that are needed to start trinity on the test data. Remember to try and use all 8 cores.
<br />

:computer: Run Trinity command
<details>
<summary>:key: Click for a complete trinity command using 8 cores</summary>
{% highlight bash %}
Trinity --seqType fa --left mouse_left.fasta --right mouse_right.fasta --SS_lib_type RF --CPU 8 --max_memory 16G --output trinity_out/
{% endhighlight %}
</details>
<br />

NB! -It is recommended to use fully specified paths for sequence files with Trinity.
    -Depending on version of Trinity used --max_memory is sometime given by the command --JM

## Exercise 2: Assess the data

Explore the Trinity output file Trinity.fasta located in the trinity\_out_dir/output directory (or output directory you specify).
Transcripts are grouped as follows: * components: the set of all sequences that share at least one k-mer (including paralogs) * contigs: transcripts that share a number of k-mers (the set of isoforms of a gene) * sequences (isoforms and allelic variation)

:computer: Count the number of sequences in the Trinity.fasta file (hint: try using the unix commands 'grep' and 'wc')
<details>
<summary>:key: Click to see how one can count sequences</summary>
{% highlight bash %}
grep ">" -c
{% endhighlight %}
</details>
<br />
<br />
:open_mouth: What is the -c switch doing?
<br />
<br />
:computer: Get basic information about the assembly with TrinityStats.
{% highlight bash %}
/sw/apps/bioinfo/trinity/2.1.0/milou/util/TrinityStats.pl Trinity.fasta
{% endhighlight %}

- How many "genes" did Trinity assemble? 
- How many transcripts?
- How large is the assembly? (nr of bases)
- What is N50?

:computer: Filter out sequences shorter than 1000 nucleotides 
hint: do a web search for appropriate tools. Someone else must have had the exact same problem. Count the number of sequences again.
<details>
<summary>:key: Click to a solution</summary>
{% highlight bash %}
module load Fastx
fasta_formatter -i Trinity.fasta -o Trinity.formated  
fastx_clipper -l 1000 -i Trinity.formated -o Trinity1000.fasta
{% endhighlight %}
</details>
<br />

:open_mouth: What is the fasta_formatter step doing?
<br />

Align some sequences to a protein database and assess full-lengthness using NCBI blast database. Also try to see if you can find instances of spliced genes in your data by using the UCSC genome browser (do a web search to find it) 

- Select BLAT from the menu at the top of the page and paste in a mouse transcript sequence from Trinity.fasta.
- Select the mouse/mm10 genome and click “submit”.
- Click on the top scoring hit.

Examine the alignments by clicking “details” on the resulting page.
- Your sequences will be displayed in the browser.
- Enable the mouse annotations (ENSEMBL gene build, UCSC genes, human proteins etc.).

Optional: Do a new transcriptome assembly of whitefly RNAseq data using above code as help.

<br />
<br />
[Jump to the top](#begin)

# Closing remarks and where to go next
It is not possible to learn RNA-seq data processing and analysis in one day... The good news is that there are many available tools and well-written tutorial with examples to learn from. In this tutorial we have covered the most important data processing steps that may be enough when the libraries are good. If not, there is plenty of trouble-shooting that one can try before discarding the data. And once the count table are in place, the biostatistical and data mining begins. There are no well-defined solutions here, all depends on the experiment and questions to be asked, but we strongly advise learning R. Not only to use the specifically designed statistical packages to analyze NGS count data, but also to be able to handle the data and results as well as to generate high-quality plots. There is no better way of learning than to try...

For those interested in RNA-seq analysis Scilifelab offer a more advanced course in RNA-sequnence analysis each semester. If you also have in interest in learning R we do for the first time this year offer a one-week introduction course in R programming. For more information on both of of these courses see [Courses offered by Scilifelab](https://www.scilifelab.se/education/courses/).
<br />
<br />
[Jump to the top](#begin)

# <a name="read"></a> More reading
- Robinson, MD, and Oshlack, A (2010). A scaling normalization method for differential expression analysis of RNA-seq data. Genome Biology 11, R25.


# About authors
Thomas Källman :neckbeard:, Agata Smialowska :smiling_imp:, Olga Dethlefsen :angel: @ NBIS, National Bioinformatics Infrastructure Sweden
<br />
<br />
[Jump to the top](#begin)
This should start the IGV so that it is visible on your screen. If not please try to
reconnect to Uppmax or consider running IGV locally as that is often
the fastest and most convinient solution. 